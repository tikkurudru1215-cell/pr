import React, { useState, useRef, useEffect } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { 
  X, 
  Mic, 
  Send, 
  Volume2, 
  Minimize2, 
  MicOff, 
  ChevronUp, 
  ChevronDown 
} from 'lucide-react';

interface AIAssistantProps {
  isOpen: boolean;
  onClose: () => void;
}

interface Message {
  id: string;
  type: 'user' | 'ai';
  content: string;
  timestamp: Date;
  isVoice?: boolean;
}

// --- NEW LANGUAGE DETECTION FUNCTION ---
const detectContentLanguage = (text: string): 'hi-IN' | 'en-US' => {
  const hindiChars = /[\u0900-\u097F]/; 
  return hindiChars.test(text) ? 'hi-IN' : 'en-US';
};
// ----------------------------------------

const AIAssistant: React.FC<AIAssistantProps> = ({ isOpen, onClose }) => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputValue, setInputValue] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isMinimized, setIsMinimized] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [voiceSupported, setVoiceSupported] = useState(false);
  const [conversationId, setConversationId] = useState<string | null>(null);
  
  const [isQuickActionsVisible, setIsQuickActionsVisible] = useState(false);

  const messagesEndRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLInputElement>(null);
  const recognitionRef = useRef<any>(null);
  const synthRef = useRef<SpeechSynthesis | null>(null);
  
  const [voices, setVoices] = useState<{ hi: SpeechSynthesisVoice | null, en: SpeechSynthesisVoice | null }>({ hi: null, en: null });


  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages, isQuickActionsVisible]); 

  // Initialize Speech Synthesis and Speech Recognition
  useEffect(() => {
    if ('speechSynthesis' in window) {
      synthRef.current = window.speechSynthesis;

      const loadVoices = () => {
        const availableVoices = synthRef.current?.getVoices();
        
        const hiVoice = availableVoices?.find(voice =>
          voice.lang.includes('hi') || voice.lang.includes('IN')
        ) || availableVoices?.find(voice => voice.lang.includes('en-IN') || voice.lang.includes('en-US'));

        const enVoice = availableVoices?.find(voice =>
            voice.lang.includes('en-US') || voice.lang.includes('en-GB')
        );

        setVoices({ hi: hiVoice || null, en: enVoice || null });
      };

      loadVoices();
      synthRef.current.onvoiceschanged = loadVoices;
    }

    const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;

    if (SpeechRecognition) {
      setVoiceSupported(true);
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = false;
      recognitionRef.current.interimResults = false;
      recognitionRef.current.lang = 'hi-IN';

      recognitionRef.current.onstart = () => {
        setIsListening(true);
      };

      recognitionRef.current.onresult = (event: any) => {
        const transcript = event.results[0][0].transcript;
        setInputValue(transcript);
        setIsListening(false);
        setTimeout(() => {
          handleSendMessage(transcript, true);
        }, 500);
      };

      recognitionRef.current.onerror = (event: any) => {
        console.error('Speech recognition error:', event.error);
        setIsListening(false);
        const errorMessage = getErrorMessage(event.error);
        console.error(`Voice input error: ${errorMessage}`);
      };

      recognitionRef.current.onend = () => {
        setIsListening(false);
      };
    } else {
      setVoiceSupported(false);
    }

    if (isOpen && messages.length === 0) {
      const initialMessage: Message = {
        id: 'welcome-1',
        type: 'ai',
        content: '‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ Digital Saathi ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™‡§ï‡•ã ‡§ï‡§ø‡§∏ ‡§ö‡•Ä‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ö‡§æ‡§π‡§ø‡§è? ‡§Ü‡§™ ‡§¨‡•ã‡§≤ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ ‡§≤‡§ø‡§ñ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§',
        timestamp: new Date()
      };
      setMessages([initialMessage]);
      setTimeout(() => {
        speakText(initialMessage.content);
      }, 1000);
    }
  }, [isOpen]);

  const getErrorMessage = (error: string) => {
    switch (error) {
      case 'no-speech':
        return '‡§ï‡•ã‡§à ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§®‡§π‡•Ä‡§Ç ‡§∏‡•Å‡§®‡§æ‡§à ‡§¶‡•Ä‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§';
      case 'audio-capture':
        return '‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡•ã‡§® ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§Ç ‡§î‡§∞ ‡§´‡§ø‡§∞ ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§';
      case 'not-allowed':
        return '‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡•ã‡§® ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§Ç‡•§ Settings ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§ï‡§∞ microphone ‡§ï‡•ã allow ‡§ï‡§∞‡•á‡§Ç‡•§';
      default:
        return 'Voice recognition ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§';
    }
  };

  const speakText = (text: string) => {
    if (synthRef.current) {
      synthRef.current.cancel();
      setIsSpeaking(true);
      const utterance = new SpeechSynthesisUtterance(text);
      
      const langCode = detectContentLanguage(text); 
      
      utterance.lang = langCode;
      
      if (langCode === 'hi-IN' && voices.hi) {
        utterance.voice = voices.hi;
      } else if (langCode === 'en-US' && voices.en) {
        utterance.voice = voices.en;
      }
      
      utterance.rate = 1.0; 
      utterance.pitch = 1;
      utterance.volume = 1;

      utterance.onstart = () => {
        setIsSpeaking(true);
      };
      utterance.onend = () => {
        setIsSpeaking(false);
      };
      utterance.onerror = (event) => {
        console.error('Speech synthesis error:', event.error);
        setIsSpeaking(false);
      };
      synthRef.current.speak(utterance);
    }
  };

  const stopSpeaking = () => {
    if (synthRef.current) {
      synthRef.current.cancel();
      setIsSpeaking(false);
    }
  };

  const handleVoiceInput = () => {
    if (!voiceSupported) {
      console.error('‡§Ü‡§™‡§ï‡§æ browser voice recognition support ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞‡§§‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ Chrome, Firefox ‡§Ø‡§æ Edge ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§');
      return;
    }

    if (isListening) {
      recognitionRef.current?.stop();
      setIsListening(false);
    } else {
      try {
        setIsListening(true);
        recognitionRef.current?.start();
      } catch (error) {
        console.error('Error starting voice recognition:', error);
        setIsListening(false);
        console.error('Voice recognition start ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ microphone ‡§ï‡•Ä permission check ‡§ï‡§∞‡•á‡§Ç‡•§');
      }
    }
  };

  const handleSendMessage = async (messageText?: string, isVoiceMessage = false) => {
    const text = messageText || inputValue;
    if (!text.trim()) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      type: 'user',
      content: text,
      timestamp: new Date(),
      isVoice: isVoiceMessage,
    };

    setMessages(prev => [...prev, userMessage]);
    setInputValue('');

    const typingMessage: Message = {
      id: 'typing',
      type: 'ai',
      content: '‡§ü‡§æ‡§á‡§™ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à...',
      timestamp: new Date()
    };
    setMessages(prev => [...prev, typingMessage]);

    try {
      const API_URL = import.meta.env.VITE_API_URL || 'http://localhost:5000';

      const response = await fetch(`${API_URL}/api/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          userId: 'guest_user', 
          message: text,
          conversationId: conversationId,
        }),
      });

      const data = await response.json();
      
      if (response.status !== 200) {
        throw new Error(data.error || "Backend server returned an error status.");
      }

      setConversationId(data.conversationId);

      setMessages(prev => {
        const newMessages = prev.filter(msg => msg.id !== 'typing');
        const aiMessage: Message = {
          id: (Date.now() + 1).toString(),
          type: 'ai',
          content: data.aiResponse,
          timestamp: new Date(),
        };
        return [...newMessages, aiMessage];
      });

      setTimeout(() => {
        speakText(data.aiResponse);
      }, 500);

    } catch (error) {
      console.error('Failed to send message:', error);
      setMessages(prev => prev.filter(msg => msg.id !== 'typing'));
      const errorMessage: Message = {
        id: (Date.now() + 1).toString(),
        type: 'ai',
        content: `‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§™‡§æ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ï‡•Å‡§õ ‡§∏‡§Æ‡§Ø ‡§¨‡§æ‡§¶ ‡§´‡§ø‡§∞ ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§ (Error: ${error instanceof Error ? error.message.substring(0, 50) + '...' : 'Unknown'})`,
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, errorMessage]);
    }
  };

// START of Quick Actions Change
// Updated Quick Actions list as requested
¬† const quickActions = [
¬† ¬† // Grievance Tool-based (Kept)
¬† ¬† 'üí° ‡§¨‡§ø‡§ú‡§≤‡•Ä ‡§ï‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§ï‡§∞‡§®‡•Ä ‡§π‡•à',
    // Education Help (Kept)
¬† ¬† 'üìö ‡§õ‡§æ‡§§‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§‡§ø ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä',
    // Technical Support (Kept)
    'üñ•Ô∏è ‡§Æ‡•á‡§∞‡§æ ‡§ê‡§™ ‡§ï‡§æ‡§Æ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à',
    // Emergency/Geospatial (Kept)
    'üö® ‡§®‡§ú‡§¶‡•Ä‡§ï‡•Ä ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§ï‡§π‡§æ‡§Å ‡§π‡•à',
    // NEW: Water Problem (Maps to 'Water Problem' service and complainService)
    'üí¶ ‡§™‡§æ‡§®‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§Ü ‡§∞‡§π‡§æ ‡§π‡•à', 
    // NEW: Scheme Lookup (Maps to 'getSchemeAndEducationData' tool)
    'üèòÔ∏è ‡§™‡•Ä‡§è‡§Æ ‡§Ü‡§µ‡§æ‡§∏ ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä', 
¬† ];
// END of Quick Actions Change

  if (!isOpen) return null;

  return (
    <AnimatePresence>
      <motion.div
        className="fixed inset-0 z-50 flex items-center justify-center p-0 sm:p-8 max-h-screen overflow-y-auto"
        initial={{ opacity: 0 }}
        animate={{ opacity: 1 }}
        exit={{ opacity: 0 }}
      >
        {/* Backdrop: Lightened background dimming */}
        <motion.div
          className="absolute inset-0 bg-gray-500/50 backdrop-blur-sm"
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
          exit={{ opacity: 0 }}
          onClick={onClose}
        />

        {/* Chat Window: Light theme box */}
        <motion.div
          className={`relative bg-backgroundCard border border-gray-300 rounded-none sm:rounded-3xl shadow-2xl w-full max-w-full lg:max-w-4xl xl:max-w-5xl flex flex-col transition-all duration-300 text-textDark`}
          initial={{ scale: 0.8, opacity: 0 }}
          animate={{ scale: 1, opacity: 1 }}
          exit={{ scale: 0.8, opacity: 0 }}
          transition={{ type: "spring", damping: 20, stiffness: 300 }}
        >
          {/* Header (Top part) - Light background, dark text */}
          <div className="flex items-center justify-between p-3 sm:p-4 border-b border-gray-200 flex-shrink-0">
            {/* Left side (Avatar and Status) */}
            <div className="flex items-center space-x-3 sm:space-x-4">
              <motion.div
                className="w-10 h-10 sm:w-12 sm:h-12 bg-gradient-to-r from-primary-600 to-accentPrimary-500 rounded-full flex items-center justify-center shadow-lg flex-shrink-0"
                animate={{ scale: [1, 1.1, 1] }}
                transition={{ duration: 2, repeat: Infinity }}
              >
                <span className="text-xl sm:text-lg text-white">ü§ñ</span>
              </motion.div>
              <div>
                <h3 className="text-lg sm:text-xl font-bold text-textDark leading-tight">Digital Saathi AI</h3>
                <div className="flex items-center space-x-2">
                  <div className="w-2 h-2 bg-green-600 rounded-full animate-pulse"></div>
                  <span className="text-green-600 font-medium text-xs">
                    {voiceSupported ? 'Voice Ready üé§' : 'Text Only üìù'}
                  </span>
                </div>
              </div>
            </div>

            {/* Right side (Controls) */}
            <div className="flex items-center space-x-2 sm:space-x-3 flex-shrink-0">
              {isSpeaking && (
                <motion.button
                  onClick={stopSpeaking}
                  className="hidden sm:flex items-center space-x-2 bg-red-100 hover:bg-red-200 px-3 sm:px-4 py-1 rounded-full transition-colors"
                  animate={{ opacity: [0.7, 1, 0.7] }}
                  transition={{ duration: 1, repeat: Infinity }}
                >
                  <Volume2 className="w-4 h-4 text-red-600" />
                  <span className="text-red-600 text-sm">‡§¨‡•ã‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à - ‡§∞‡•ã‡§ï‡•á‡§Ç</span>
                </motion.button>
              )}
              {/* MINIMIZE button */}
              <motion.button
                onClick={() => setIsMinimized(!isMinimized)}
                className="p-2 sm:p-2 hover:bg-gray-100 rounded-full transition-colors"
                whileHover={{ scale: 1.1 }}
                whileTap={{ scale: 0.9 }}
              >
                <Minimize2 className="w-5 h-5 sm:w-5 sm:h-5 text-textMuted" />
              </motion.button>
              {/* CLOSE button (across sign) */}
              <motion.button
                onClick={onClose}
                className="p-2 sm:p-2 hover:bg-gray-100 rounded-full transition-colors"
                whileHover={{ scale: 1.1 }}
                whileTap={{ scale: 0.9 }}
              >
                <X className="w-5 h-5 sm:w-5 sm:h-5 text-textMuted" />
              </motion.button>
            </div>
          </div>

          {!isMinimized && (
            <>
              {/* Messages (The big text chat area) */}
              <div className="flex-1 overflow-y-auto p-4 sm:p-6 space-y-6 bg-backgroundLight"> {/* Light background for chat area */}
                {messages.map((message) => (
                  <motion.div
                    key={message.id}
                    className={`flex ${message.type === 'user' ? 'justify-end' : 'justify-start'}`}
                    initial={{ opacity: 0, y: 20 }}
                    animate={{ opacity: 1, y: 0 }}
                    transition={{ duration: 0.3 }}
                  >
                    <div
                      className={`max-w-xs sm:max-w-lg px-4 sm:px-6 py-3 sm:py-4 rounded-2xl ${
                        // Light theme message bubbles
                        message.type === 'user'
                          ? 'bg-primary-600 text-white' // User text remains white on blue background
                          : message.id === 'typing'
                          ? 'bg-gray-100 text-textMuted border border-gray-300'
                          : 'bg-backgroundCard border border-gray-200 text-textDark'
                      }`}
                    >
                      <div className="flex items-center justify-between mb-1 sm:mb-2">
                        <div className="flex items-center space-x-2">
                          {message.type === 'user' ? (
                            <span className="text-sm font-medium">‡§Ü‡§™</span>
                          ) : (
                            <span className="text-sm font-medium text-textDark">ü§ñ Digital Saathi</span>
                          )}
                          {message.isVoice && (
                            <span className="text-xs bg-black/10 px-2 py-1 rounded-full text-white">üé§ Voice</span>
                          )}
                        </div>
                        {message.type === 'ai' && message.id !== 'typing' && (
                          <button
                            onClick={() => speakText(message.content)}
                            className="text-xs bg-gray-100 hover:bg-gray-200 px-2 py-1 rounded-full transition-colors flex items-center space-x-1 text-primary-600"
                          >
                            <Volume2 className="w-3 h-3" />
                            <span>‡§∏‡•Å‡§®‡•á‡§Ç</span>
                          </button>
                        )}
                      </div>
                      {/* Text color based on message type */}
                      <p className={`text-sm sm:text-base leading-relaxed whitespace-pre-line ${message.type === 'ai' ? 'text-textDark' : 'text-white'}`}>{message.content}</p>
                      <p className={`text-xs mt-2 ${
                        message.type === 'user' ? 'text-white/80' : 'text-textMuted'
                      }`}>
                        {message.timestamp.toLocaleTimeString('hi-IN', {
                          hour: '2-digit',
                          minute: '2-digit'
                        })}
                      </p>
                    </div>
                  </motion.div>
                ))}
                <div ref={messagesEndRef} />
              </div>

              {/* Quick Actions (The minimized bottom section) */}
              <div className="px-4 sm:px-6 flex-shrink-0 border-t border-gray-200 pt-2 bg-backgroundCard"> {/* Light background */}
                {/* Quick Actions Header and Toggle */}
                <div className="flex items-center justify-between mb-3">
                  <p className="text-textMuted text-sm font-medium">Quick Actions - ‡§è‡§ï ‡§ï‡•ç‡§≤‡§ø‡§ï ‡§Æ‡•á‡§Ç:</p>
                  <motion.button 
                    onClick={() => setIsQuickActionsVisible(!isQuickActionsVisible)}
                    className="text-textDark p-1 rounded-full hover:bg-gray-100 transition-colors"
                    whileHover={{ scale: 1.1 }}
                    whileTap={{ scale: 0.9 }}
                    aria-label={isQuickActionsVisible ? "Minimize Quick Actions" : "Expand Quick Actions"}
                  >
                    {isQuickActionsVisible ? (
                      <ChevronDown className="w-5 h-5 text-textMuted" />
                    ) : (
                      <ChevronUp className="w-5 h-5 text-textMuted" />
                    )}
                  </motion.button>
                </div>

                {/* Quick Actions Grid (Collapsed by Default, maximizing chat area) */}
                <AnimatePresence initial={false}>
                  {isQuickActionsVisible && (
                    <motion.div
                      className="pb-4" 
                      key="quick-actions-grid"
                      initial={{ height: 0, opacity: 0 }}
                      animate={{ height: 'auto', opacity: 1 }}
                      exit={{ height: 0, opacity: 0 }}
                      transition={{ duration: 0.3 }}
                    >
                      <div className="grid grid-cols-2 md:grid-cols-3 gap-2">
                        {quickActions.map((action, index) => (
                          <motion.button
                            key={index}
                            onClick={() => handleSendMessage(action)}
                            // Light action button style
                            className="bg-gray-100 hover:bg-gray-200 border border-gray-200 rounded-xl px-3 py-2 text-sm text-textDark transition-all duration-300 text-left"
                            whileHover={{ scale: 1.02 }}
                            whileTap={{ scale: 0.98 }}
                          >
                            {action}
                          </motion.button>
                        ))}
                      </div>
                    </motion.div>
                  )}
                </AnimatePresence>
              </div>


              {/* Input (Fixed size at the bottom) */}
              <div className="px-4 sm:px-6 py-2 pt-0 flex-shrink-0 bg-backgroundCard">
                <div className="flex items-center space-x-4 bg-gray-100 border border-gray-200 rounded-2xl p-3 sm:p-4">
                  <motion.button
                    onClick={handleVoiceInput}
                    // Mic button: Blue to Teal, White icon
                    // CORRECTED CODE
className={`p-3 sm:p-4 rounded-full transition-all duration-300 ${
    isListening
        ? 'bg-red-500 animate-pulse shadow-lg' // If listening
        : voiceSupported
        ? 'bg-gradient-to-r from-primary-600 to-accentPrimary-500 hover:from-primary-700 hover:to-accentPrimary-600' // If not listening AND voice is supported
        : 'bg-gray-400 cursor-not-allowed' // If not listening AND voice is NOT supported
}`}
                    whileHover={voiceSupported ? { scale: 1.1 } : {}}
                    whileTap={voiceSupported ? { scale: 0.9 } : {}}
                    disabled={!voiceSupported}
                  >
                    {isListening ? (
                      <MicOff className="w-5 h-5 sm:w-6 sm:h-6 text-white" />
                    ) : (
                      <Mic className="w-5 h-5 sm:w-6 sm:h-6 text-white" />
                    )}
                  </motion.button>

                  <input
                    ref={inputRef}
                    type="text"
                    value={inputValue}
                    onChange={(e) => setInputValue(e.target.value)}
                    onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
                    placeholder={voiceSupported ? "‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç ‡§Ø‡§æ ‡§Æ‡§æ‡§á‡§ï ‡§¶‡§¨‡§æ‡§ï‡§∞ ‡§¨‡•ã‡§≤‡•á‡§Ç..." : "‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç..."}
                    className="flex-1 bg-transparent text-textDark placeholder-textMuted focus:outline-none text-sm sm:text-base"
                  />

                  <motion.button
                    onClick={() => handleSendMessage()}
                    // Send button: Blue to Teal
                    className="p-3 sm:p-4 bg-gradient-to-r from-primary-600 to-accentPrimary-500 hover:from-primary-700 hover:to-accentPrimary-600 rounded-full transition-all duration-300 disabled:opacity-50"
                    whileHover={{ scale: 1.1 }}
                    whileTap={{ scale: 0.9 }}
                    disabled={!inputValue.trim()}
                  >
                    <Send className="w-5 h-5 sm:w-6 sm:h-6 text-white" />
                  </motion.button>
                </div>

                {isListening && (
                  <motion.div
                    className="text-center mt-4"
                    animate={{ opacity: [0.5, 1, 0.5] }}
                    transition={{ duration: 1.5, repeat: Infinity }}
                  >
                    <p className="text-red-600 text-xl font-bold">üé§ ‡§∏‡•Å‡§® ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç... ‡§Ö‡§¨ ‡§¨‡•ã‡§≤‡§ø‡§è</p>
                    <p className="text-textMuted text-sm mt-1">‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§¨‡•ã‡§≤‡•á‡§Ç</p>
                    <div className="flex justify-center mt-3">
                      <div className="flex space-x-1">
                        {[...Array(5)].map((_, i) => (
                          <motion.div
                            key={i}
                            className="w-2 h-8 bg-red-500 rounded-full"
                            animate={{
                              scaleY: [0.3, 1, 0.3],
                            }}
                            transition={{
                              duration: 0.5,
                              repeat: Infinity,
                              delay: i * 0.1,
                            }}
                          />
                        ))}
                      </div>
                    </div>
                  </motion.div>
                )}

                {!voiceSupported && (
                  <div className="text-center mt-2">
                    <p className="text-accentSecondary-600 text-sm">
                      ‚ö†Ô∏è Voice feature ‡§ï‡•á ‡§≤‡§ø‡§è Chrome, Firefox ‡§Ø‡§æ Edge browser ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
                    </p>
                  </div>
                )}
              </div>
            </>
          )}
        </motion.div>
      </motion.div>
    </AnimatePresence>
  );
};

export default AIAssistant;