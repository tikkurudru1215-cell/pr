import React, { useState, useRef, useEffect } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { X, Mic, Send, Volume2, Minimize2, MicOff } from 'lucide-react';

interface AIAssistantProps {
  isOpen: boolean;
  onClose: () => void;
}

interface Message {
  id: string;
  type: 'user' | 'ai';
  content: string;
  timestamp: Date;
  isVoice?: boolean;
}

const AIAssistant: React.FC<AIAssistantProps> = ({ isOpen, onClose }) => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputValue, setInputValue] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isMinimized, setIsMinimized] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [voiceSupported, setVoiceSupported] = useState(false);
  const [conversationId, setConversationId] = useState<string | null>(null);

  const messagesEndRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLInputElement>(null);
  const recognitionRef = useRef<any>(null);
  const synthRef = useRef<SpeechSynthesis | null>(null);
  const [hindiVoice, setHindiVoice] = useState<SpeechSynthesisVoice | null>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  // Initialize Speech Synthesis and Speech Recognition
  useEffect(() => {
    if ('speechSynthesis' in window) {
      synthRef.current = window.speechSynthesis;

      const loadVoices = () => {
        const voices = synthRef.current?.getVoices();
        const foundHindiVoice = voices?.find(voice =>
          voice.lang.includes('hi') || voice.lang.includes('IN')
        );
        if (foundHindiVoice) {
          setHindiVoice(foundHindiVoice);
        } else {
          setHindiVoice(null);
        }
      };

      loadVoices();
      synthRef.current.onvoiceschanged = loadVoices;
    }

    const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;

    if (SpeechRecognition) {
      setVoiceSupported(true);
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = false;
      recognitionRef.current.interimResults = false;
      recognitionRef.current.lang = 'hi-IN';

      recognitionRef.current.onstart = () => {
        setIsListening(true);
      };

      recognitionRef.current.onresult = (event: any) => {
        const transcript = event.results[0][0].transcript;
        setInputValue(transcript);
        setIsListening(false);
        setTimeout(() => {
          handleSendMessage(transcript, true);
        }, 500);
      };

      recognitionRef.current.onerror = (event: any) => {
        console.error('Speech recognition error:', event.error);
        setIsListening(false);
        const errorMessage = getErrorMessage(event.error);
        // Using console error instead of alert for better UX in dev environment
        console.error(`Voice input error: ${errorMessage}`);
      };

      recognitionRef.current.onend = () => {
        setIsListening(false);
      };
    } else {
      setVoiceSupported(false);
    }

    if (isOpen && messages.length === 0) {
      const initialMessage: Message = {
        id: 'welcome-1',
        type: 'ai',
        content: 'рдирдорд╕реНрдХрд╛рд░! рдореИрдВ рдЖрдкрдХрд╛ Digital Saathi рд╣реВрдВред рдЖрдкрдХреЛ рдХрд┐рд╕ рдЪреАрдЬрд╝ рдореЗрдВ рдорджрдж рдЪрд╛рд╣рд┐рдП? рдЖрдк рдмреЛрд▓ рд╕рдХрддреЗ рд╣реИрдВ рдпрд╛ рд▓рд┐рдЦ рд╕рдХрддреЗ рд╣реИрдВред',
        timestamp: new Date()
      };
      setMessages([initialMessage]);
      setTimeout(() => {
        speakText(initialMessage.content);
      }, 1000);
    }
  }, [isOpen]);

  const getErrorMessage = (error: string) => {
    switch (error) {
      case 'no-speech':
        return 'рдХреЛрдИ рдЖрд╡рд╛рдЬрд╝ рдирд╣реАрдВ рд╕реБрдирд╛рдИ рджреАред рдХреГрдкрдпрд╛ рдлрд┐рд░ рд╕реЗ рдХреЛрд╢рд┐рд╢ рдХрд░реЗрдВред';
      case 'audio-capture':
        return 'рдорд╛рдЗрдХреНрд░реЛрдлреЛрди рдХреА рдЕрдиреБрдорддрд┐ рджреЗрдВ рдФрд░ рдлрд┐рд░ рдХреЛрд╢рд┐рд╢ рдХрд░реЗрдВред';
      case 'not-allowed':
        return 'рдорд╛рдЗрдХреНрд░реЛрдлреЛрди рдХреА рдЕрдиреБрдорддрд┐ рджреЗрдВред Settings рдореЗрдВ рдЬрд╛рдХрд░ microphone рдХреЛ allow рдХрд░реЗрдВред';
      default:
        return 'Voice recognition рдореЗрдВ рд╕рдорд╕реНрдпрд╛ рд╣реИред рдХреГрдкрдпрд╛ рдлрд┐рд░ рдХреЛрд╢рд┐рд╢ рдХрд░реЗрдВред';
    }
  };

  const speakText = (text: string) => {
    if (synthRef.current) {
      synthRef.current.cancel();
      setIsSpeaking(true);
      const utterance = new SpeechSynthesisUtterance(text);
      if (hindiVoice) {
        utterance.voice = hindiVoice;
      }
      utterance.lang = 'hi-IN';
      utterance.rate = 0.8;
      utterance.pitch = 1;
      utterance.volume = 1;

      utterance.onstart = () => {
        setIsSpeaking(true);
      };
      utterance.onend = () => {
        setIsSpeaking(false);
      };
      utterance.onerror = (event) => {
        console.error('Speech synthesis error:', event.error);
        setIsSpeaking(false);
      };
      synthRef.current.speak(utterance);
    }
  };

  const stopSpeaking = () => {
    if (synthRef.current) {
      synthRef.current.cancel();
      setIsSpeaking(false);
    }
  };

  const handleVoiceInput = () => {
    if (!voiceSupported) {
      // Use console.error instead of alert as per instructions
      console.error('рдЖрдкрдХрд╛ browser voice recognition support рдирд╣реАрдВ рдХрд░рддрд╛ред рдХреГрдкрдпрд╛ Chrome, Firefox рдпрд╛ Edge рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред');
      return;
    }

    if (isListening) {
      recognitionRef.current?.stop();
      setIsListening(false);
    } else {
      try {
        setIsListening(true);
        recognitionRef.current?.start();
      } catch (error) {
        console.error('Error starting voice recognition:', error);
        setIsListening(false);
        // Use console.error instead of alert
        console.error('Voice recognition start рдХрд░рдиреЗ рдореЗрдВ рд╕рдорд╕реНрдпрд╛ рд╣реИред рдХреГрдкрдпрд╛ microphone рдХреА permission check рдХрд░реЗрдВред');
      }
    }
  };

  const handleSendMessage = async (messageText?: string, isVoiceMessage = false) => {
    const text = messageText || inputValue;
    if (!text.trim()) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      type: 'user',
      content: text,
      timestamp: new Date(),
      isVoice: isVoiceMessage,
    };

    // Add user message to the UI
    setMessages(prev => [...prev, userMessage]);
    setInputValue('');

    // Show typing indicator while waiting for AI response
    const typingMessage: Message = {
      id: 'typing',
      type: 'ai',
      content: 'рдЯрд╛рдЗрдк рдХрд░ рд░рд╣рд╛ рд╣реИ...',
      timestamp: new Date()
    };
    setMessages(prev => [...prev, typingMessage]);

    try {
      // Get API_URL from environment variables for backend call
      const API_URL = import.meta.env.VITE_API_URL || 'http://localhost:5000';

      // Make the API call to your new backend endpoint
      const response = await fetch(`${API_URL}/api/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          userId: 'guest_user', // This could be a dynamic user ID
          message: text,
          conversationId: conversationId,
        }),
      });

      const data = await response.json();
      
      // Handle the error response from the backend server
      if (response.status !== 200) {
        throw new Error(data.error || "Backend server returned an error status.");
      }

      setConversationId(data.conversationId);

      // Remove typing indicator and add the AI's real response
      setMessages(prev => {
        const newMessages = prev.filter(msg => msg.id !== 'typing');
        const aiMessage: Message = {
          id: (Date.now() + 1).toString(),
          type: 'ai',
          content: data.aiResponse,
          timestamp: new Date(),
        };
        return [...newMessages, aiMessage];
      });

      // Speak the AI's response
      setTimeout(() => {
        speakText(data.aiResponse);
      }, 500);

    } catch (error) {
      console.error('Failed to send message:', error);
      // Remove typing indicator on error
      setMessages(prev => prev.filter(msg => msg.id !== 'typing'));
      // Add an error message to the UI
      const errorMessage: Message = {
        id: (Date.now() + 1).toString(),
        type: 'ai',
        content: `рдореИрдВ рдЖрдкрдХреА рдорджрдж рдирд╣реАрдВ рдХрд░ рдкрд╛ рд░рд╣рд╛ рд╣реВрдВред рдХреГрдкрдпрд╛ рдХреБрдЫ рд╕рдордп рдмрд╛рдж рдлрд┐рд░ рдХреЛрд╢рд┐рд╢ рдХрд░реЗрдВред (Error: ${error instanceof Error ? error.message.substring(0, 50) + '...' : 'Unknown'})`,
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, errorMessage]);
    }
  };

  // src/components/AIAssistant.tsx

// ... (existing code)

┬а const quickActions = [
┬а ┬а // Grievance Tool-based
┬а ┬а 'ЁЯТб рдмрд┐рдЬрд▓реА рдХреА рд╢рд┐рдХрд╛рдпрдд рдХрд░рдиреА рд╣реИ',
    // Geospatial Tool-based
┬а ┬а 'ЁЯПе рдирдЬрджреАрдХреА рдЕрд╕реНрдкрддрд╛рд▓ рдХрд╣рд╛рдБ рд╣реИ',
    // Agriculture Tool-based
┬а ┬а 'ЁЯЪЬ рдЧреЗрд╣реВрдВ рдХрд╛ рдордВрдбреА рднрд╛рд╡ рдХреНрдпрд╛ рд╣реИ',
    // Canned Response/Form-based
┬а ┬а 'ЁЯПЫя╕П рд╕рд░рдХрд╛рд░реА рдлреЙрд░реНрдо рднрд░рдирд╛ рд╣реИ',
┬а ┬а 'ЁЯУЪ рдЫрд╛рддреНрд░рд╡реГрддреНрддрд┐ рдХреА рдЬрд╛рдирдХрд╛рд░реА',
┬а ┬а 'ЁЯТз рдкрд╛рдиреА рдХреА рд╕рдорд╕реНрдпрд╛ рд╣реИ',
┬а ];

// ... (rest of the file remains the same)

  if (!isOpen) return null;

  return (
    <AnimatePresence>
      <motion.div
        // Added max-h-screen and overflow-y-auto to the outer container
        // This ensures the whole modal fits within the viewport.
        className="fixed inset-0 z-50 flex items-center justify-center p-4 max-h-screen overflow-y-auto"
        initial={{ opacity: 0 }}
        animate={{ opacity: 1 }}
        exit={{ opacity: 0 }}
      >
        {/* Backdrop */}
        <motion.div
          className="absolute inset-0 bg-black/70 backdrop-blur-sm"
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
          exit={{ opacity: 0 }}
          onClick={onClose}
        />

        {/* Chat Window: Adjusted height to be responsive and smaller */}
        <motion.div
          className={`relative bg-white/10 backdrop-blur-xl border border-white/20 rounded-3xl shadow-2xl w-full max-w-full sm:max-w-xl md:max-w-2xl flex flex-col transition-all duration-300 ${
            isMinimized ? 'h-20' : 'h-[90vh] max-h-[800px]' // Set height to 90vh on all screen sizes, capped at 800px
          }`}
          initial={{ scale: 0.8, opacity: 0 }}
          animate={{ scale: 1, opacity: 1 }}
          exit={{ scale: 0.8, opacity: 0 }}
          transition={{ type: "spring", damping: 20, stiffness: 300 }}
        >
          {/* Header */}
          <div className="flex items-center justify-between p-4 sm:p-6 border-b border-white/10 flex-shrink-0">
            {/* Left side (Avatar and Status) */}
            <div className="flex items-center space-x-3 sm:space-x-4">
              <motion.div
                className="w-12 h-12 sm:w-16 sm:h-16 bg-gradient-to-r from-primary-500 to-purple-600 rounded-full flex items-center justify-center shadow-lg flex-shrink-0"
                animate={{ scale: [1, 1.1, 1] }}
                transition={{ duration: 2, repeat: Infinity }}
              >
                <span className="text-xl sm:text-2xl">ЁЯдЦ</span>
              </motion.div>
              <div>
                <h3 className="text-lg sm:text-2xl font-bold text-white leading-tight">Digital Saathi AI</h3>
                <div className="flex items-center space-x-2">
                  <div className="w-3 h-3 bg-green-400 rounded-full animate-pulse"></div>
                  <span className="text-green-400 font-medium text-xs sm:text-sm">
                    {voiceSupported ? 'Voice Ready ЁЯОд' : 'Text Only ЁЯУЭ'}
                  </span>
                </div>
              </div>
            </div>

            {/* Right side (Controls) */}
            <div className="flex items-center space-x-2 sm:space-x-3 flex-shrink-0">
              {isSpeaking && (
                <motion.button
                  onClick={stopSpeaking}
                  className="hidden sm:flex items-center space-x-2 bg-red-500/20 hover:bg-red-500/30 px-3 sm:px-4 py-2 rounded-full transition-colors"
                  animate={{ opacity: [0.7, 1, 0.7] }}
                  transition={{ duration: 1, repeat: Infinity }}
                >
                  <Volume2 className="w-4 h-4 text-red-400" />
                  <span className="text-red-400 text-sm">рдмреЛрд▓ рд░рд╣рд╛ рд╣реИ - рд░реЛрдХреЗрдВ</span>
                </motion.button>
              )}
              {/* MINIMIZE button visibility fix: increased touch target size */}
              <motion.button
                onClick={() => setIsMinimized(!isMinimized)}
                className="p-2 sm:p-3 hover:bg-white/10 rounded-full transition-colors"
                whileHover={{ scale: 1.1 }}
                whileTap={{ scale: 0.9 }}
              >
                <Minimize2 className="w-5 h-5 sm:w-6 sm:h-6 text-gray-400" />
              </motion.button>
              {/* CLOSE button visibility fix: increased touch target size */}
              <motion.button
                onClick={onClose}
                className="p-2 sm:p-3 hover:bg-white/10 rounded-full transition-colors"
                whileHover={{ scale: 1.1 }}
                whileTap={{ scale: 0.9 }}
              >
                <X className="w-5 h-5 sm:w-6 sm:h-6 text-gray-400" />
              </motion.button>
            </div>
          </div>

          {!isMinimized && (
            <>
              {/* Messages: flex-1 for scrolling content area */}
              <div className="flex-1 overflow-y-auto p-4 sm:p-6 space-y-6">
                {messages.map((message) => (
                  <motion.div
                    key={message.id}
                    className={`flex ${message.type === 'user' ? 'justify-end' : 'justify-start'}`}
                    initial={{ opacity: 0, y: 20 }}
                    animate={{ opacity: 1, y: 0 }}
                    transition={{ duration: 0.3 }}
                  >
                    <div
                      className={`max-w-xs sm:max-w-lg px-4 sm:px-6 py-3 sm:py-4 rounded-2xl ${ // Adjusted max-width for mobile
                        message.type === 'user'
                          ? 'bg-gradient-to-r from-primary-500 to-purple-600 text-white'
                          : message.id === 'typing'
                          ? 'bg-gray-500/20 text-gray-300 border border-gray-500/30'
                          : 'bg-white/10 text-white border border-white/20'
                      }`}
                    >
                      <div className="flex items-center justify-between mb-1 sm:mb-2">
                        <div className="flex items-center space-x-2">
                          {message.type === 'user' ? (
                            <span className="text-sm font-medium">рдЖрдк</span>
                          ) : (
                            <span className="text-sm font-medium">ЁЯдЦ Digital Saathi</span>
                          )}
                          {message.isVoice && (
                            <span className="text-xs bg-white/20 px-2 py-1 rounded-full">ЁЯОд Voice</span>
                          )}
                        </div>
                        {message.type === 'ai' && message.id !== 'typing' && (
                          <button
                            onClick={() => speakText(message.content)}
                            className="text-xs bg-white/20 hover:bg-white/30 px-2 py-1 rounded-full transition-colors flex items-center space-x-1"
                          >
                            <Volume2 className="w-3 h-3" />
                            <span>рд╕реБрдиреЗрдВ</span>
                          </button>
                        )}
                      </div>
                      <p className="text-sm sm:text-base leading-relaxed whitespace-pre-line">{message.content}</p>
                      <p className={`text-xs mt-2 ${
                        message.type === 'user' ? 'text-white/70' : 'text-gray-400'
                      }`}>
                        {message.timestamp.toLocaleTimeString('hi-IN', {
                          hour: '2-digit',
                          minute: '2-digit'
                        })}
                      </p>
                    </div>
                  </motion.div>
                ))}
                <div ref={messagesEndRef} />
              </div>

              {/* Quick Actions and Input are fixed at the bottom (flex-shrink-0) */}
              <div className="px-4 sm:px-6 pb-4 flex-shrink-0">
                <p className="text-gray-400 text-sm mb-3">Quick Actions - рдПрдХ рдХреНрд▓рд┐рдХ рдореЗрдВ:</p>
                <div className="grid grid-cols-2 md:grid-cols-3 gap-2">
                  {quickActions.map((action, index) => (
                    <motion.button
                      key={index}
                      onClick={() => handleSendMessage(action)}
                      className="bg-white/10 hover:bg-white/20 border border-white/20 rounded-xl px-3 py-2 text-sm text-white transition-all duration-300 text-left"
                      whileHover={{ scale: 1.02 }}
                      whileTap={{ scale: 0.98 }}
                    >
                      {action}
                    </motion.button>
                  ))}
                </div>
              </div>

              {/* Input is fixed at the bottom (flex-shrink-0) */}
              <div className="p-4 sm:p-6 pt-0 flex-shrink-0">
                <div className="flex items-center space-x-4 bg-white/10 border border-white/20 rounded-2xl p-3 sm:p-4">
                  <motion.button
                    onClick={handleVoiceInput}
                    className={`p-3 sm:p-4 rounded-full transition-all duration-300 ${
                      isListening
                        ? 'bg-red-500 animate-pulse shadow-lg'
                        : voiceSupported
                        ? 'bg-gradient-to-r from-primary-500 to-purple-600 hover:from-primary-600 hover:to-purple-700'
                        : 'bg-gray-500 cursor-not-allowed'
                    }`}
                    whileHover={voiceSupported ? { scale: 1.1 } : {}}
                    whileTap={voiceSupported ? { scale: 0.9 } : {}}
                    disabled={!voiceSupported}
                  >
                    {isListening ? (
                      <MicOff className="w-5 h-5 sm:w-6 sm:h-6 text-white" />
                    ) : (
                      <Mic className="w-5 h-5 sm:w-6 sm:h-6 text-white" />
                    )}
                  </motion.button>

                  <input
                    ref={inputRef}
                    type="text"
                    value={inputValue}
                    onChange={(e) => setInputValue(e.target.value)}
                    onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
                    placeholder={voiceSupported ? "рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ рдпрд╛ рдорд╛рдЗрдХ рджрдмрд╛рдХрд░ рдмреЛрд▓реЗрдВ..." : "рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ..."}
                    className="flex-1 bg-transparent text-white placeholder-gray-400 focus:outline-none text-sm sm:text-base"
                  />

                  <motion.button
                    onClick={() => handleSendMessage()}
                    className="p-3 sm:p-4 bg-gradient-to-r from-primary-500 to-purple-600 hover:from-primary-600 hover:to-purple-700 rounded-full transition-all duration-300 disabled:opacity-50"
                    whileHover={{ scale: 1.1 }}
                    whileTap={{ scale: 0.9 }}
                    disabled={!inputValue.trim()}
                  >
                    <Send className="w-5 h-5 sm:w-6 sm:h-6 text-white" />
                  </motion.button>
                </div>

                {isListening && (
                  <motion.div
                    className="text-center mt-4"
                    animate={{ opacity: [0.5, 1, 0.5] }}
                    transition={{ duration: 1.5, repeat: Infinity }}
                  >
                    <p className="text-red-400 text-xl font-bold">ЁЯОд рд╕реБрди рд░рд╣рд╛ рд╣реВрдВ... рдЕрдм рдмреЛрд▓рд┐рдП</p>
                    <p className="text-gray-400 text-sm mt-1">рд╕реНрдкрд╖реНрдЯ рдЖрд╡рд╛рдЬрд╝ рдореЗрдВ рдмреЛрд▓реЗрдВ</p>
                    <div className="flex justify-center mt-3">
                      <div className="flex space-x-1">
                        {[...Array(5)].map((_, i) => (
                          <motion.div
                            key={i}
                            className="w-2 h-8 bg-red-400 rounded-full"
                            animate={{
                              scaleY: [0.3, 1, 0.3],
                            }}
                            transition={{
                              duration: 0.5,
                              repeat: Infinity,
                              delay: i * 0.1,
                            }}
                          />
                        ))}
                      </div>
                    </div>
                  </motion.div>
                )}

                {!voiceSupported && (
                  <div className="text-center mt-2">
                    <p className="text-yellow-400 text-sm">
                      тЪая╕П Voice feature рдХреЗ рд▓рд┐рдП Chrome, Firefox рдпрд╛ Edge browser рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ
                    </p>
                  </div>
                )}
              </div>
            </>
          )}
        </motion.div>
      </motion.div>
    </AnimatePresence>
  );
};

export default AIAssistant;