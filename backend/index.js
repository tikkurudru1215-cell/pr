// backend/index.js

import dotenv from "dotenv";
import { fileURLToPath } from "url";
import path from "path";
import express from "express";
import bodyParser from "body-parser";
import cors from "cors";
import mongoose from "mongoose";
import axios from "axios"; 
import { compareTwoStrings } from 'string-similarity'; 

import { complainService, complainServiceToolDefinition } from "./ai/tools/complain-service.js"; 
import { getNearbyService, getNearbyServiceToolDefinition } from "./ai/tools/geospatial-service.js"; 
import { getAgricultureData, getAgricultureDataToolDefinition } from "./ai/tools/agriculture-service.js"; 
import { getSchemeAndEducationData, getSchemeAndEducationDataToolDefinition } from "./ai/tools/finance-education-service.js"; 

import Service from "./models/Service.js";
import Conversation from "./models/Conversation.js";
import Message from "./models/Message.js";

// --- Setup File Paths and .env ---
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const envPath = path.resolve(__dirname, '..', '.env');
dotenv.config({ path: envPath });

const app = express();
const PORT = process.env.PORT || 5000;

app.use(cors());
app.use(bodyParser.json());

// --- Database Connection ---
const MONGO_URI = process.env.MONGO_URI;
console.log("Loaded MONGO_URI:", MONGO_URI ? "âœ… Found" : "âŒ Missing");

mongoose.connect(MONGO_URI)
    .then(() => console.log('âœ… MongoDB connected successfully.'))
    .catch(err => {
        console.error('âŒ MongoDB connection error:', err.message);
        console.error('   Please ensure your MongoDB server is running on the URI specified in backend/.env');
    });

// --- OpenRouter AI Setup ---
const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY || process.env.OPENAI_API_KEY; 
const OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions";
const AI_MODEL = "openai/gpt-4o-mini"; 

console.log("Loaded AI_API_KEY:", OPENROUTER_API_KEY ? "âœ… Found" : "âŒ Missing");

// --- Tool/Function Definitions and Map ---
const toolFunctions = {
    complainService,
    getNearbyService,
    getAgricultureData, 
    getSchemeAndEducationData, 
};

// Map tool definitions to OpenRouter/OpenAI format (type: 'function' required)
const toolDefinitions = [
    complainServiceToolDefinition,
    getNearbyServiceToolDefinition,
    getAgricultureDataToolDefinition, 
    getSchemeAndEducationDataToolDefinition, 
].map(def => ({
    type: 'function',
    function: def,
}));


// --- OpenRouter API Call Handler (Replaces SDK Logic) ---
async function callOpenRouterAPI(messages, toolDefinitions) {
    if (!OPENROUTER_API_KEY) {
        throw new Error("OpenRouter API Key is missing.");
    }
    
    // FIX: Simplified the message mapping logic in the handler. Messages array is now pre-formatted before being passed here.
    const openRouterMessages = messages.map(msg => {
        if (msg.role === 'ai') {
            return { role: 'assistant', content: msg.content };
        } else if (msg.role === 'tool') {
            // Tool messages are expected to be in the final API format { role: 'tool', tool_call_id: '...', content: '...' }
            return msg;
        }
        return msg; // user role
    });

    const body = {
        model: AI_MODEL,
        messages: openRouterMessages,
        tools: toolDefinitions,
        temperature: 0.2,
        // Optional attribution headers for OpenRouter visibility
        extra_body: {
             "prompt_language": "hi-IN",
        }
    };
    
    // Add system instruction as the first message
    const systemInstruction = `You are "Digital Saathi AI", an expert voice-first government service assistant operating in India.
Your primary language is Hindi (Devanagari script), but you are fluent in English.
Your goal is to guide the user through government processes, file complaints (which are saved locally), and provide necessary information using your internal knowledge base and mock data tools.
You DO NOT have access to live external APIs like NCH or OpenWeatherMap, so you must rely on the mock data provided by your tools.
For all other queries, answer directly.
Maintain a helpful, encouraging, and authoritative tone.`;

    body.messages.unshift({
        role: 'system',
        content: systemInstruction
    });

    const headers = {
        'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
        'Content-Type': 'application/json',
        'HTTP-Referer': 'digital-saathi-ai.app', 
        'X-Title': 'Digital Saathi AI', 
    };

    // Added 25-second timeout for stability
    const response = await axios.post(OPENROUTER_URL, body, { 
        headers,
        timeout: 25000, 
    });
    return response.data;
}

// --- NEW: Google Search Handler for General Queries ---
/**
 * Performs a Google Search and returns a formatted snippet of the top result.
 * This acts as the "Real Search Tool" fallback.
 * @param {string} query The user's message to search for.
 * @returns {Promise<string>} A formatted string with the search snippet, or an empty string.
 */
async function performGoogleSearch(query) {
    // The Google Search tool is available in this environment
    try {
        const searchResults = await google.search({ queries: [query] });
        
        if (searchResults.results && searchResults.results.length > 0) {
            const topResult = searchResults.results[0];
            let snippet = topResult.snippet || topResult.title;

            // Append the search result to the AI's response for contextually new/fresh information
            return `\n\nðŸ”Ž **Real-time Search Result**: ${snippet} (Source: ${topResult.source_title || topResult.source})`;
        }
        return "";
    } catch (error) {
        // Log the error but don't fail the entire request
        console.error("âŒ Google Search Fallback failed:", error);
        return "";
    }
}


// --- Main Logic: Chat Endpoint (/api/chat) ---
app.post("/api/chat", async (req, res) => {
    const { message: userMessage, conversationId } = req.body;
    
    if (!userMessage) {
        return res.status(400).json({ aiResponse: "âŒ Please provide a message" });
    }

    try {
        // 1. Service Matching Logic (Canned Responses - Fast NLP Filter)
        const services = await Service.find({}).lean();
        let cannedResponse = null;
        const THRESHOLD = 0.7; 

        for (const service of services) {
            const allMatchableTerms = [service.name, service.description, ...service.keywords];

            for (const term of allMatchableTerms) {
                const similarity = compareTwoStrings(userMessage.toLowerCase(), term.toLowerCase());
                
                if (similarity > THRESHOLD) {
                    cannedResponse = service;
                    break;
                }
            }
            if (cannedResponse) break;
        }

        if (cannedResponse) {
            return res.json({ 
                aiResponse: cannedResponse.response,
                serviceMatched: cannedResponse.name,
                conversationId: conversationId 
            });
        }
        
        // 2. Fallback to OpenRouter for Tool/General Queries (Core LLM NLP)
        if (!OPENROUTER_API_KEY) {
             return res.status(500).json({ 
                aiResponse: "à¤®à¤¾à¤«à¤¼ à¤•à¤°à¤¨à¤¾, à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤šà¥ˆà¤Ÿ à¤•à¥‡ à¤²à¤¿à¤ OpenRouter API Key à¤¸à¥‡à¤Ÿ à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆà¥¤",
                error: "OpenRouter API key missing for fallback chat."
            });
        }

        // Find or create conversation and fetch history
        let currentConversationId = conversationId;
        if (!currentConversationId || currentConversationId === 'null') {
            const newConversation = new Conversation({ userId: 'guest_user', title: userMessage.substring(0, 30) });
            await newConversation.save();
            currentConversationId = newConversation._id;
        }

        let history = await Message.find({ conversationId: currentConversationId })
            .sort({ timestamp: 1 })
            .select('role content')
            .lean();

        // CRITICAL FIX LOCATION 1: Convert MongoDB history messages to OpenRouter API format
        let messages = history.map(msg => {
             if (msg.role === 'tool') {
                 // msg.content is the stringified JSON object of the DB result
                 const dbResult = JSON.parse(msg.content); 
                 return {
                     role: 'tool',
                     tool_call_id: dbResult.tool_call_id,
                     content: dbResult.response_content,
                 };
             }
             return { role: msg.role === 'ai' ? 'assistant' : msg.role, content: msg.content };
        });
        
        // Add current user message
        messages.push({ role: 'user', content: userMessage });

        let response = await callOpenRouterAPI(messages, toolDefinitions);
        
        let aiResponse = response.choices[0].message.content;
        let toolCalls = response.choices[0].message.tool_calls;
        let finalAIResponse = aiResponse;
        let searchAppend = "";
        
        // Step 2a: Check for function calls (Tool Execution)
        if (toolCalls && toolCalls.length > 0) {
            
            // Add the model's message requesting tool execution to messages array for the next call
            messages.push({
                role: 'assistant',
                tool_calls: toolCalls,
                content: aiResponse || null 
            });
            
            for (const call of toolCalls) {
                const func = toolFunctions[call.function.name];
                if (!func) {
                    throw new Error(`Unknown function call: ${call.function.name}`);
                }
                
                const args = JSON.parse(call.function.arguments);
                const result = await func(args, { Service }); 
                
                // CRITICAL FIX: The content sent back to the model MUST be the stringified JSON object of the tool result.
                const toolContentString = JSON.stringify(result); 

                // Prepare DB save object
                const dbToolResult = {
                     tool_call_id: call.id,
                     response_content: toolContentString, // Store the final content string (JSON.stringify(result))
                };

                // Save tool call/result to history immediately
                await Message.create({ 
                    conversationId: currentConversationId, 
                    role: 'tool', 
                    content: JSON.stringify(dbToolResult), 
                });

                // CRITICAL FIX LOCATION 2: Prepare the EPHEMERAL message for the second API call
                messages.push({
                    role: 'tool',
                    tool_call_id: call.id, 
                    content: toolContentString, 
                });
            }

            // Call OpenRouter again with tool results appended
            response = await callOpenRouterAPI(messages, toolDefinitions);
            finalAIResponse = response.choices[0].message.content;
            
        } else if (aiResponse?.length > 0) {
            // Step 2b: No tool call, LLM provided a direct answer. Augment with search if it's a general query.
            
            const isToolQuery = Object.values(toolDefinitions).some(def => 
                userMessage.toLowerCase().includes(def.function.name.toLowerCase()) || 
                userMessage.toLowerCase().includes(def.function.description.toLowerCase())
            );

            // If the LLM gives a direct answer and it wasn't a tool/service query, use search fallback.
            const isGeneralQuery = !isToolQuery; 
            
            if (isGeneralQuery) {
                searchAppend = await performGoogleSearch(userMessage);
                finalAIResponse = aiResponse + searchAppend;
            } else {
                finalAIResponse = aiResponse;
            }
        }
        
        // 3. Save new messages
        await Message.insertMany([
            { conversationId: currentConversationId, role: 'user', content: userMessage },
            { conversationId: currentConversationId, role: 'ai', content: finalAIResponse },
        ]);

        res.json({ aiResponse: finalAIResponse, conversationId: currentConversationId });

    } catch (err) {
        // Error Handling
        console.error("âŒ Critical chat processing error:", err);
        
        let customMessage = "à¤®à¤¾à¤«à¤¼ à¤•à¤°à¤¨à¤¾, à¤®à¥‡à¤°à¥‡ AI à¤¸à¤¿à¤¸à¥à¤Ÿà¤® à¤®à¥‡à¤‚ à¤•à¥‹à¤ˆ à¤¤à¤•à¤¨à¥€à¤•à¥€ à¤¸à¤®à¤¸à¥à¤¯à¤¾ à¤† à¤—à¤ˆ à¤¹à¥ˆà¥¤";
        let statusCode = 500;

        // Check for common Axios/HTTP errors
        if (axios.isAxiosError(err) && err.response) {
            statusCode = err.response.status;
            if (statusCode === 401) {
                 customMessage = "OpenRouter API Key à¤…à¤®à¤¾à¤¨à¥à¤¯ à¤¹à¥ˆà¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤ªà¤¨à¥€ Key à¤”à¤° Billing (à¤¬à¤¿à¤²à¤¿à¤‚à¤—) à¤œà¤¾à¤‚à¤šà¥‡à¤‚à¥¤";
            } else if (statusCode === 429) {
                 customMessage = "OpenRouter à¤•à¥€ à¤¦à¤° à¤¸à¥€à¤®à¤¾ (Rate Limit) à¤ªà¤¾à¤° à¤¹à¥‹ à¤—à¤ˆ à¤¹à¥ˆà¥¤";
            } else {
                 customMessage = `OpenRouter à¤¸à¥‡ à¤•à¤¨à¥‡à¤•à¥à¤Ÿ à¤•à¤°à¤¨à¥‡ à¤®à¥‡à¤‚ HTTP à¤¤à¥à¤°à¥à¤Ÿà¤¿ (${statusCode})à¥¤`;
            }
        }
        // Handle timeout error
        else if (axios.isAxiosError(err) && err.code === 'ECONNABORTED') {
             customMessage = "à¤•à¥à¤·à¤®à¤¾ à¤•à¤°à¥‡à¤‚, AI à¤®à¥‰à¤¡à¤² à¤¸à¥‡ à¤œà¤µà¤¾à¤¬ à¤†à¤¨à¥‡ à¤®à¥‡à¤‚ à¤¬à¤¹à¥à¤¤ à¤¦à¥‡à¤° à¤¹à¥‹ à¤—à¤ˆà¥¤";
             statusCode = 504; 
        }
        // Specific tool execution error handling (Includes the error the user is seeing)
        // If the error message is related to property reading, it means a structural error.
        else if (err.message.includes("Cannot read properties of undefined") || 
                 err.message.includes("tool_call_id") || 
                 err.message.includes("functionResponse")) {
             customMessage = "à¤•à¥à¤·à¤®à¤¾ à¤•à¤°à¥‡à¤‚, à¤Ÿà¥‚à¤² à¤•à¥‡ à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ à¤•à¥‹ à¤¸à¤‚à¤¸à¤¾à¤§à¤¿à¤¤ (process) à¤•à¤°à¤¨à¥‡ à¤®à¥‡à¤‚ à¤à¤• à¤†à¤‚à¤¤à¤°à¤¿à¤• à¤¤à¥à¤°à¥à¤Ÿà¤¿ à¤¹à¥à¤ˆà¥¤";
             statusCode = 500;
        }
        else if (err.message.includes('MongooseError') || err.message.includes('connect')) {
            customMessage = "à¤¡à¥‡à¤Ÿà¤¾à¤¬à¥‡à¤¸ à¤•à¤¨à¥‡à¤•à¥à¤¶à¤¨ à¤®à¥‡à¤‚ à¤¸à¤®à¤¸à¥à¤¯à¤¾ à¤¹à¥ˆà¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¸à¥à¤¨à¤¿à¤¶à¥à¤šà¤¿à¤¤ à¤•à¤°à¥‡à¤‚ à¤•à¤¿ MongoDB à¤šà¤² à¤°à¤¹à¤¾ à¤¹à¥ˆà¥¤";
        }
        
        res.status(statusCode).json({ 
            aiResponse: `${customMessage} (Error: ${err.message.substring(0, 50)}...)`,
            error: err.message 
        });
    }
});


// --- Services Endpoint (/api/services) ---
app.get('/api/services', async (req, res) => {
    try {
        const services = await Service.find({}).lean(); 
        res.json(services);
    } catch (error) {
        console.error('âŒ Error fetching services:', error.message);
        res.status(500).json({ message: 'Failed to load services. Check backend connectivity and seed data.' });
    }
}
);


app.listen(PORT, () => {
    console.log(`âœ… Backend running on http://localhost:${PORT}`);
});